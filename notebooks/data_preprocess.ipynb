{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Склеивание тестового датасета и перевод его в parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_folder_path = \"data\"\n",
    "output_parquet_path = \"output_dataset.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [pl.read_csv(os.path.join(csv_folder_path, file)) for file in os.listdir(csv_folder_path) if file.endswith(\".csv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pl.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.write_parquet(output_parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Склеивание учебного датасета и перевод его в parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_csv(\"data/train_6.csv\")\n",
    "data.write_parquet(\"data/train_6.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(csv_folder_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        data = pl.read_csv(os.path.join(csv_folder_path, file))\n",
    "        data.write_parquet(os.path.join(csv_folder_path, file.replace(\"csv\", \"parquet\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pl.read_parquet(\"data/train_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(shape: (5, 503)\n",
       " ┌────────┬───────┬─────┬───────────┬───┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
       " │ target ┆ smpl  ┆ id  ┆ feature_1 ┆ … ┆ feature_497 ┆ feature_498 ┆ feature_499 ┆ feature_500 │\n",
       " │ ---    ┆ ---   ┆ --- ┆ ---       ┆   ┆ ---         ┆ ---         ┆ ---         ┆ ---         │\n",
       " │ i64    ┆ str   ┆ i64 ┆ f32       ┆   ┆ f32         ┆ f32         ┆ f32         ┆ f32         │\n",
       " ╞════════╪═══════╪═════╪═══════════╪═══╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
       " │ 0      ┆ train ┆ 0   ┆ 0.372342  ┆ … ┆ 1.45386     ┆ -0.83348    ┆ 0.184028    ┆ -0.438225   │\n",
       " │ 0      ┆ train ┆ 1   ┆ 0.382215  ┆ … ┆ 0.491954    ┆ -0.003686   ┆ 0.46972     ┆ -1.094604   │\n",
       " │ 0      ┆ train ┆ 2   ┆ 0.472528  ┆ … ┆ 0.147941    ┆ -0.007553   ┆ -0.981296   ┆ 0.27093     │\n",
       " │ 0      ┆ train ┆ 3   ┆ 0.51226   ┆ … ┆ 0.000645    ┆ 0.674715    ┆ 0.803094    ┆ 1.037068    │\n",
       " │ 0      ┆ train ┆ 4   ┆ 1.487986  ┆ … ┆ 0.458768    ┆ -0.444558   ┆ -0.33371    ┆ 0.380206    │\n",
       " └────────┴───────┴─────┴───────────┴───┴─────────────┴─────────────┴─────────────┴─────────────┘,\n",
       " (3592376, 503))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head(), combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = pl.read_parquet(\"data/train_6.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in dataframes.columns:\n",
    "    if dataframes[columns].dtype == pl.Float64:\n",
    "        dataframes = dataframes.with_columns(dataframes[columns].cast(pl.Float32, strict=False).alias(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pl.concat([combined_df, dataframes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4490468, 503)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 503)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target</th><th>smpl</th><th>id</th><th>feature_1</th><th>feature_2</th><th>feature_3</th><th>feature_4</th><th>feature_5</th><th>feature_6</th><th>feature_7</th><th>feature_8</th><th>feature_9</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>feature_33</th><th>feature_34</th><th>&hellip;</th><th>feature_464</th><th>feature_465</th><th>feature_466</th><th>feature_467</th><th>feature_468</th><th>feature_469</th><th>feature_470</th><th>feature_471</th><th>feature_472</th><th>feature_473</th><th>feature_474</th><th>feature_475</th><th>feature_476</th><th>feature_477</th><th>feature_478</th><th>feature_479</th><th>feature_480</th><th>feature_481</th><th>feature_482</th><th>feature_483</th><th>feature_484</th><th>feature_485</th><th>feature_486</th><th>feature_487</th><th>feature_488</th><th>feature_489</th><th>feature_490</th><th>feature_491</th><th>feature_492</th><th>feature_493</th><th>feature_494</th><th>feature_495</th><th>feature_496</th><th>feature_497</th><th>feature_498</th><th>feature_499</th><th>feature_500</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>0</td><td>&quot;train&quot;</td><td>0</td><td>0.372342</td><td>1.500852</td><td>2.133451</td><td>-0.957384</td><td>-0.119022</td><td>0.12292</td><td>0.150993</td><td>0.506717</td><td>-0.839165</td><td>-0.199743</td><td>0.216119</td><td>1.348401</td><td>1.065637</td><td>-0.946945</td><td>0.499681</td><td>-0.264383</td><td>0.0</td><td>-1.33332</td><td>0.443795</td><td>0.098801</td><td>0.0</td><td>0.0</td><td>0.015876</td><td>-0.021957</td><td>0.792371</td><td>0.013245</td><td>0.0</td><td>1.017209</td><td>-0.448728</td><td>0.492206</td><td>0.0</td><td>-0.851639</td><td>0.936328</td><td>0.264994</td><td>&hellip;</td><td>-0.645828</td><td>0.434229</td><td>1.816138</td><td>-1.108658</td><td>0.826718</td><td>-1.196374</td><td>0.24742</td><td>0.160462</td><td>-0.039017</td><td>0.499748</td><td>0.159741</td><td>0.425718</td><td>1.162702</td><td>-0.632753</td><td>-0.517942</td><td>0.449427</td><td>0.077546</td><td>-1.703537</td><td>0.005984</td><td>-0.873771</td><td>-0.246468</td><td>1.4243</td><td>0.340689</td><td>-0.663166</td><td>0.517225</td><td>-0.286324</td><td>57.0</td><td>-1.254497</td><td>0.0</td><td>0.803635</td><td>-1.017931</td><td>-0.52113</td><td>0.647187</td><td>1.45386</td><td>-0.83348</td><td>0.184028</td><td>-0.438225</td></tr><tr><td>0</td><td>&quot;train&quot;</td><td>1</td><td>0.382215</td><td>0.962629</td><td>-0.192558</td><td>-1.019986</td><td>-1.330412</td><td>-0.100149</td><td>-1.131326</td><td>-1.173272</td><td>-1.790011</td><td>0.116708</td><td>0.788913</td><td>0.720656</td><td>-0.914471</td><td>-0.766861</td><td>1.551133</td><td>-0.198539</td><td>0.0</td><td>-0.71487</td><td>-0.869011</td><td>-0.743693</td><td>0.0</td><td>0.0</td><td>-0.767664</td><td>1.141277</td><td>-1.286912</td><td>-0.572806</td><td>0.0</td><td>-1.158312</td><td>-2.049119</td><td>-0.193137</td><td>0.0</td><td>-0.554452</td><td>0.632568</td><td>-1.332586</td><td>&hellip;</td><td>-0.126592</td><td>-0.614043</td><td>0.021234</td><td>-0.334816</td><td>-0.055649</td><td>1.201724</td><td>-0.281092</td><td>-1.279436</td><td>0.674947</td><td>-0.198981</td><td>-0.614454</td><td>-1.006725</td><td>-0.103481</td><td>0.778153</td><td>-1.090015</td><td>0.810727</td><td>1.101775</td><td>-0.761821</td><td>-0.112268</td><td>-0.491775</td><td>1.130508</td><td>-0.989669</td><td>1.19114</td><td>-0.803186</td><td>0.566153</td><td>1.284961</td><td>1.0</td><td>-0.884458</td><td>0.0</td><td>-1.643735</td><td>-1.264842</td><td>-1.523788</td><td>0.604948</td><td>0.491954</td><td>-0.003686</td><td>0.46972</td><td>-1.094604</td></tr><tr><td>0</td><td>&quot;train&quot;</td><td>2</td><td>0.472528</td><td>-0.695334</td><td>0.537968</td><td>-0.033</td><td>-0.36485</td><td>-0.441849</td><td>-0.035953</td><td>-0.921158</td><td>0.746746</td><td>0.477138</td><td>1.061066</td><td>2.348964</td><td>-0.740345</td><td>1.007488</td><td>0.990622</td><td>-1.122783</td><td>0.0</td><td>0.632436</td><td>-0.006833</td><td>-0.411626</td><td>0.0</td><td>0.0</td><td>-1.270903</td><td>-1.879841</td><td>0.62167</td><td>-0.688338</td><td>0.0</td><td>2.160033</td><td>-1.6759</td><td>-0.082673</td><td>0.0</td><td>-0.148567</td><td>-0.46428</td><td>-0.178598</td><td>&hellip;</td><td>0.869195</td><td>1.376578</td><td>0.750041</td><td>1.620765</td><td>-0.959123</td><td>-0.757372</td><td>-1.331277</td><td>-0.710401</td><td>-1.513987</td><td>0.720477</td><td>-1.287441</td><td>0.10716</td><td>1.086501</td><td>-0.458318</td><td>-0.072571</td><td>0.470386</td><td>1.170615</td><td>0.213452</td><td>1.806888</td><td>-2.085279</td><td>-1.035103</td><td>-0.173536</td><td>-0.470982</td><td>-0.134215</td><td>0.129898</td><td>-0.146585</td><td>2.0</td><td>-0.322682</td><td>0.0</td><td>-0.496765</td><td>-0.051931</td><td>0.743209</td><td>-1.395109</td><td>0.147941</td><td>-0.007553</td><td>-0.981296</td><td>0.27093</td></tr><tr><td>0</td><td>&quot;train&quot;</td><td>3</td><td>0.51226</td><td>-1.23196</td><td>0.555326</td><td>1.456647</td><td>1.435357</td><td>0.168613</td><td>-0.628737</td><td>0.249797</td><td>1.475977</td><td>-0.169269</td><td>0.51034</td><td>0.911377</td><td>-0.23678</td><td>-0.625305</td><td>2.107196</td><td>1.295551</td><td>0.0</td><td>0.649062</td><td>-0.117766</td><td>-1.508139</td><td>0.0</td><td>0.0</td><td>-0.387628</td><td>0.545191</td><td>0.14498</td><td>1.372529</td><td>0.0</td><td>0.05125</td><td>1.53818</td><td>0.840503</td><td>0.0</td><td>-0.385656</td><td>0.915411</td><td>-1.591858</td><td>&hellip;</td><td>1.28186</td><td>0.303849</td><td>0.803946</td><td>1.482661</td><td>-0.109579</td><td>1.002381</td><td>-0.432043</td><td>-0.381731</td><td>0.017506</td><td>-0.059549</td><td>-1.383963</td><td>0.008786</td><td>-1.59286</td><td>3.101853</td><td>0.318749</td><td>0.923378</td><td>-0.717617</td><td>0.383301</td><td>-1.171417</td><td>0.411504</td><td>1.426704</td><td>-0.174565</td><td>1.742944</td><td>0.697967</td><td>0.590742</td><td>-0.22384</td><td>3.0</td><td>0.976566</td><td>0.0</td><td>1.183049</td><td>-0.178662</td><td>1.468147</td><td>-0.791254</td><td>0.000645</td><td>0.674715</td><td>0.803094</td><td>1.037068</td></tr><tr><td>0</td><td>&quot;train&quot;</td><td>4</td><td>1.487986</td><td>-0.164392</td><td>-1.197163</td><td>1.549057</td><td>0.952673</td><td>1.144201</td><td>-0.964</td><td>0.0319</td><td>1.262253</td><td>-0.456219</td><td>-0.55885</td><td>0.035832</td><td>-1.898993</td><td>0.24009</td><td>0.788041</td><td>0.478828</td><td>1.0</td><td>0.30892</td><td>-0.966941</td><td>-0.525692</td><td>0.0</td><td>1.0</td><td>0.065214</td><td>-0.504748</td><td>0.022186</td><td>0.760587</td><td>0.0</td><td>2.040007</td><td>0.220125</td><td>1.336657</td><td>0.0</td><td>0.360773</td><td>0.636532</td><td>0.425884</td><td>&hellip;</td><td>-1.107146</td><td>-0.20163</td><td>-0.084249</td><td>0.321524</td><td>0.170648</td><td>-1.102571</td><td>-1.281386</td><td>0.066872</td><td>0.297046</td><td>-1.016946</td><td>0.109061</td><td>-0.03387</td><td>-0.053841</td><td>1.302263</td><td>-0.773607</td><td>-0.266053</td><td>0.577491</td><td>0.229705</td><td>0.77006</td><td>-0.297142</td><td>0.205571</td><td>-1.949414</td><td>-0.018187</td><td>-0.667887</td><td>-1.840382</td><td>-0.582842</td><td>4.0</td><td>-1.655236</td><td>0.0</td><td>1.076122</td><td>-0.555735</td><td>1.248728</td><td>-0.485943</td><td>0.458768</td><td>-0.444558</td><td>-0.33371</td><td>0.380206</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 503)\n",
       "┌────────┬───────┬─────┬───────────┬───┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ target ┆ smpl  ┆ id  ┆ feature_1 ┆ … ┆ feature_497 ┆ feature_498 ┆ feature_499 ┆ feature_500 │\n",
       "│ ---    ┆ ---   ┆ --- ┆ ---       ┆   ┆ ---         ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ i64    ┆ str   ┆ i64 ┆ f32       ┆   ┆ f32         ┆ f32         ┆ f32         ┆ f32         │\n",
       "╞════════╪═══════╪═════╪═══════════╪═══╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ 0      ┆ train ┆ 0   ┆ 0.372342  ┆ … ┆ 1.45386     ┆ -0.83348    ┆ 0.184028    ┆ -0.438225   │\n",
       "│ 0      ┆ train ┆ 1   ┆ 0.382215  ┆ … ┆ 0.491954    ┆ -0.003686   ┆ 0.46972     ┆ -1.094604   │\n",
       "│ 0      ┆ train ┆ 2   ┆ 0.472528  ┆ … ┆ 0.147941    ┆ -0.007553   ┆ -0.981296   ┆ 0.27093     │\n",
       "│ 0      ┆ train ┆ 3   ┆ 0.51226   ┆ … ┆ 0.000645    ┆ 0.674715    ┆ 0.803094    ┆ 1.037068    │\n",
       "│ 0      ┆ train ┆ 4   ┆ 1.487986  ┆ … ┆ 0.458768    ┆ -0.444558   ┆ -0.33371    ┆ 0.380206    │\n",
       "└────────┴───────┴─────┴───────────┴───┴─────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.sort(by=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4490468, 503)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in combined_df.columns:\n",
    "    if combined_df[columns].dtype == pl.Float64:\n",
    "        combined_df = combined_df.with_columns(combined_df[columns].cast(pl.Float32, strict=False).alias(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.write_parquet(\"data/train_dataset.parquet\", compression=\"zstd\", compression_level=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dfgds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 503)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target</th><th>smpl</th><th>id</th><th>feature_1</th><th>feature_2</th><th>feature_3</th><th>feature_4</th><th>feature_5</th><th>feature_6</th><th>feature_7</th><th>feature_8</th><th>feature_9</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>feature_33</th><th>feature_34</th><th>&hellip;</th><th>feature_464</th><th>feature_465</th><th>feature_466</th><th>feature_467</th><th>feature_468</th><th>feature_469</th><th>feature_470</th><th>feature_471</th><th>feature_472</th><th>feature_473</th><th>feature_474</th><th>feature_475</th><th>feature_476</th><th>feature_477</th><th>feature_478</th><th>feature_479</th><th>feature_480</th><th>feature_481</th><th>feature_482</th><th>feature_483</th><th>feature_484</th><th>feature_485</th><th>feature_486</th><th>feature_487</th><th>feature_488</th><th>feature_489</th><th>feature_490</th><th>feature_491</th><th>feature_492</th><th>feature_493</th><th>feature_494</th><th>feature_495</th><th>feature_496</th><th>feature_497</th><th>feature_498</th><th>feature_499</th><th>feature_500</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>&quot;train&quot;</td><td>0</td><td>0.372342</td><td>1.5008518</td><td>2.133451</td><td>-0.957384</td><td>-0.119022</td><td>0.1229198</td><td>0.150993</td><td>0.506717</td><td>-0.839165</td><td>-0.199743</td><td>0.216119</td><td>1.3484006</td><td>1.065637</td><td>-0.946945</td><td>0.4996807</td><td>-0.264383</td><td>0.0</td><td>-1.33332</td><td>0.443795</td><td>0.098801</td><td>0.0</td><td>0.0</td><td>0.015876</td><td>-0.021957</td><td>0.7923714</td><td>0.013245</td><td>0.0</td><td>1.0172088</td><td>-0.448728</td><td>0.492206</td><td>0.0</td><td>-0.851639</td><td>0.9363277</td><td>0.264994</td><td>&hellip;</td><td>-0.645828</td><td>0.4342295</td><td>1.8161377</td><td>-1.108658</td><td>0.8267176</td><td>-1.196374</td><td>0.24742</td><td>0.160462</td><td>-0.039017</td><td>0.499748</td><td>0.159741</td><td>0.425718</td><td>1.1627017</td><td>-0.632753</td><td>-0.517942</td><td>0.449427</td><td>0.077546</td><td>-1.703537</td><td>0.005984</td><td>-0.873771</td><td>-0.246468</td><td>1.4243001</td><td>0.340689</td><td>-0.663166</td><td>0.5172254</td><td>-0.286324</td><td>57.0</td><td>-1.254497</td><td>0.0</td><td>0.8036352</td><td>-1.017931</td><td>-0.52113</td><td>0.6471875</td><td>1.4538602</td><td>-0.83348</td><td>0.184028</td><td>-0.438225</td></tr><tr><td>0</td><td>&quot;train&quot;</td><td>1</td><td>0.382215</td><td>0.9626286</td><td>-0.192558</td><td>-1.019986</td><td>-1.330412</td><td>-0.100149</td><td>-1.131326</td><td>-1.173272</td><td>-1.790011</td><td>0.116708</td><td>0.7889134</td><td>0.720656</td><td>-0.914471</td><td>-0.766861</td><td>1.5511327</td><td>-0.198539</td><td>0.0</td><td>-0.71487</td><td>-0.869011</td><td>-0.743693</td><td>0.0</td><td>0.0</td><td>-0.767664</td><td>1.1412772</td><td>-1.286912</td><td>-0.572805</td><td>0.0</td><td>-1.158312</td><td>-2.04912</td><td>-0.193137</td><td>0.0</td><td>-0.554452</td><td>0.6325681</td><td>-1.332586</td><td>&hellip;</td><td>-0.126592</td><td>-0.614043</td><td>0.0212341</td><td>-0.334816</td><td>-0.055649</td><td>1.2017244</td><td>-0.281092</td><td>-1.279436</td><td>0.674947</td><td>-0.198981</td><td>-0.614454</td><td>-1.006725</td><td>-0.103481</td><td>0.778153</td><td>-1.090015</td><td>0.810727</td><td>1.1017752</td><td>-0.761821</td><td>-0.112268</td><td>-0.491775</td><td>1.130508</td><td>-0.989669</td><td>1.1911404</td><td>-0.803186</td><td>0.5661534</td><td>1.2849605</td><td>1.0</td><td>-0.884458</td><td>0.0</td><td>-1.643735</td><td>-1.264842</td><td>-1.523788</td><td>0.604948</td><td>0.491954</td><td>-0.003686</td><td>0.4697199</td><td>-1.094604</td></tr><tr><td>0</td><td>&quot;train&quot;</td><td>2</td><td>0.472528</td><td>-0.695334</td><td>0.537968</td><td>-0.033</td><td>-0.36485</td><td>-0.441849</td><td>-0.035953</td><td>-0.921158</td><td>0.746746</td><td>0.4771376</td><td>1.0610658</td><td>2.3489637</td><td>-0.740345</td><td>1.007488</td><td>0.9906224</td><td>-1.122783</td><td>0.0</td><td>0.632436</td><td>-0.006833</td><td>-0.411627</td><td>0.0</td><td>0.0</td><td>-1.270903</td><td>-1.879841</td><td>0.6216702</td><td>-0.688338</td><td>0.0</td><td>2.1600327</td><td>-1.6759</td><td>-0.082673</td><td>0.0</td><td>-0.148567</td><td>-0.46428</td><td>-0.178598</td><td>&hellip;</td><td>0.8691954</td><td>1.3765785</td><td>0.750041</td><td>1.620765</td><td>-0.959123</td><td>-0.757373</td><td>-1.331277</td><td>-0.710402</td><td>-1.513987</td><td>0.720477</td><td>-1.287441</td><td>0.10716</td><td>1.0865015</td><td>-0.458318</td><td>-0.072571</td><td>0.470386</td><td>1.1706146</td><td>0.213452</td><td>1.8068883</td><td>-2.085279</td><td>-1.035103</td><td>-0.173536</td><td>-0.470982</td><td>-0.134215</td><td>0.129898</td><td>-0.146585</td><td>2.0</td><td>-0.322682</td><td>0.0</td><td>-0.496765</td><td>-0.051931</td><td>0.7432095</td><td>-1.395109</td><td>0.147941</td><td>-0.007553</td><td>-0.981296</td><td>0.27093</td></tr><tr><td>0</td><td>&quot;train&quot;</td><td>3</td><td>0.5122596</td><td>-1.23196</td><td>0.5553261</td><td>1.4566467</td><td>1.4353575</td><td>0.1686132</td><td>-0.628737</td><td>0.249797</td><td>1.4759773</td><td>-0.169269</td><td>0.5103397</td><td>0.911377</td><td>-0.23678</td><td>-0.625305</td><td>2.1071956</td><td>1.2955506</td><td>0.0</td><td>0.6490616</td><td>-0.117766</td><td>-1.508139</td><td>0.0</td><td>0.0</td><td>-0.387628</td><td>0.5451911</td><td>0.14498</td><td>1.372529</td><td>0.0</td><td>0.05125</td><td>1.5381795</td><td>0.8405032</td><td>0.0</td><td>-0.385656</td><td>0.9154105</td><td>-1.591858</td><td>&hellip;</td><td>1.2818605</td><td>0.303849</td><td>0.803946</td><td>1.4826615</td><td>-0.109579</td><td>1.0023811</td><td>-0.432043</td><td>-0.381731</td><td>0.017506</td><td>-0.059549</td><td>-1.383962</td><td>0.008786</td><td>-1.59286</td><td>3.1018534</td><td>0.318749</td><td>0.923378</td><td>-0.717617</td><td>0.383301</td><td>-1.171417</td><td>0.411504</td><td>1.4267044</td><td>-0.174565</td><td>1.7429444</td><td>0.6979669</td><td>0.5907423</td><td>-0.22384</td><td>3.0</td><td>0.976566</td><td>0.0</td><td>1.1830486</td><td>-0.178662</td><td>1.4681466</td><td>-0.791254</td><td>0.000645</td><td>0.674715</td><td>0.803094</td><td>1.037068</td></tr><tr><td>0</td><td>&quot;train&quot;</td><td>4</td><td>1.4879864</td><td>-0.164392</td><td>-1.197163</td><td>1.5490566</td><td>0.9526726</td><td>1.1442006</td><td>-0.964</td><td>0.0318995</td><td>1.262253</td><td>-0.456219</td><td>-0.55885</td><td>0.035832</td><td>-1.898993</td><td>0.24009</td><td>0.7880415</td><td>0.478828</td><td>1.0</td><td>0.3089197</td><td>-0.966941</td><td>-0.525692</td><td>0.0</td><td>1.0</td><td>0.065214</td><td>-0.504748</td><td>0.022186</td><td>0.7605866</td><td>0.0</td><td>2.040007</td><td>0.2201252</td><td>1.336657</td><td>0.0</td><td>0.360773</td><td>0.636532</td><td>0.4258841</td><td>&hellip;</td><td>-1.107146</td><td>-0.20163</td><td>-0.084249</td><td>0.321524</td><td>0.170648</td><td>-1.102571</td><td>-1.281386</td><td>0.066872</td><td>0.297046</td><td>-1.016946</td><td>0.109061</td><td>-0.03387</td><td>-0.053841</td><td>1.3022635</td><td>-0.773607</td><td>-0.266053</td><td>0.577491</td><td>0.229705</td><td>0.77006</td><td>-0.297142</td><td>0.2055708</td><td>-1.949415</td><td>-0.018187</td><td>-0.667887</td><td>-1.840383</td><td>-0.582842</td><td>4.0</td><td>-1.655236</td><td>0.0</td><td>1.0761224</td><td>-0.555735</td><td>1.2487283</td><td>-0.485943</td><td>0.4587679</td><td>-0.444558</td><td>-0.33371</td><td>0.380206</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 503)\n",
       "┌────────┬───────┬─────┬───────────┬───┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ target ┆ smpl  ┆ id  ┆ feature_1 ┆ … ┆ feature_497 ┆ feature_498 ┆ feature_499 ┆ feature_500 │\n",
       "│ ---    ┆ ---   ┆ --- ┆ ---       ┆   ┆ ---         ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ i64    ┆ str   ┆ i64 ┆ f64       ┆   ┆ f64         ┆ f64         ┆ f64         ┆ f64         │\n",
       "╞════════╪═══════╪═════╪═══════════╪═══╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ 0      ┆ train ┆ 0   ┆ 0.372342  ┆ … ┆ 1.4538602   ┆ -0.83348    ┆ 0.184028    ┆ -0.438225   │\n",
       "│ 0      ┆ train ┆ 1   ┆ 0.382215  ┆ … ┆ 0.491954    ┆ -0.003686   ┆ 0.4697199   ┆ -1.094604   │\n",
       "│ 0      ┆ train ┆ 2   ┆ 0.472528  ┆ … ┆ 0.147941    ┆ -0.007553   ┆ -0.981296   ┆ 0.27093     │\n",
       "│ 0      ┆ train ┆ 3   ┆ 0.5122596 ┆ … ┆ 0.000645    ┆ 0.674715    ┆ 0.803094    ┆ 1.037068    │\n",
       "│ 0      ┆ train ┆ 4   ┆ 1.4879864 ┆ … ┆ 0.4587679   ┆ -0.444558   ┆ -0.33371    ┆ 0.380206    │\n",
       "└────────┴───────┴─────┴───────────┴───┴─────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pl.read_parquet(\"data/train_1-002.parquet\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in data.columns:\n",
    "    if data[columns].dtype == pl.Float64:\n",
    "        data = data.with_columns(data[columns].cast(pl.Float32, strict=False).alias(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(\"smpl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 504)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>target</th><th>smpl</th><th>id</th><th>feature_1</th><th>feature_2</th><th>feature_3</th><th>feature_4</th><th>feature_5</th><th>feature_6</th><th>feature_7</th><th>feature_8</th><th>feature_9</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>feature_33</th><th>&hellip;</th><th>feature_464</th><th>feature_465</th><th>feature_466</th><th>feature_467</th><th>feature_468</th><th>feature_469</th><th>feature_470</th><th>feature_471</th><th>feature_472</th><th>feature_473</th><th>feature_474</th><th>feature_475</th><th>feature_476</th><th>feature_477</th><th>feature_478</th><th>feature_479</th><th>feature_480</th><th>feature_481</th><th>feature_482</th><th>feature_483</th><th>feature_484</th><th>feature_485</th><th>feature_486</th><th>feature_487</th><th>feature_488</th><th>feature_489</th><th>feature_490</th><th>feature_491</th><th>feature_492</th><th>feature_493</th><th>feature_494</th><th>feature_495</th><th>feature_496</th><th>feature_497</th><th>feature_498</th><th>feature_499</th><th>feature_500</th></tr><tr><td>str</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>449046.0</td><td>&quot;449046&quot;</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>&hellip;</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td><td>449046.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>&quot;0&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>0.011551</td><td>null</td><td>224522.5</td><td>-0.033924</td><td>-0.00611</td><td>0.016456</td><td>-0.046785</td><td>0.050992</td><td>0.009004</td><td>-0.023415</td><td>-0.10847</td><td>-0.008339</td><td>-0.025386</td><td>-0.086228</td><td>0.502751</td><td>-0.023261</td><td>-0.117075</td><td>0.009337</td><td>-0.063689</td><td>0.249179</td><td>-0.009792</td><td>0.033657</td><td>-0.021057</td><td>0.1585</td><td>0.249179</td><td>0.019193</td><td>0.003554</td><td>0.031133</td><td>-0.002671</td><td>0.071405</td><td>0.024551</td><td>-0.037627</td><td>-0.032464</td><td>0.12227</td><td>0.000702</td><td>0.052095</td><td>&hellip;</td><td>-0.005741</td><td>0.015001</td><td>-0.040843</td><td>-0.001003</td><td>0.000644</td><td>-0.003894</td><td>-0.135432</td><td>-0.017948</td><td>-0.002468</td><td>-0.062583</td><td>0.015995</td><td>-0.014824</td><td>-0.078167</td><td>0.082329</td><td>-0.005962</td><td>-0.015322</td><td>-0.082777</td><td>-0.099434</td><td>0.055482</td><td>-0.025645</td><td>-0.011117</td><td>0.004557</td><td>0.013971</td><td>-0.022661</td><td>-0.057921</td><td>0.00049</td><td>14.639001</td><td>-0.063176</td><td>0.1585</td><td>-0.053474</td><td>-0.067469</td><td>-0.013554</td><td>-0.075068</td><td>-0.001039</td><td>-0.038255</td><td>-0.030217</td><td>0.046983</td></tr><tr><td>&quot;std&quot;</td><td>0.106854</td><td>null</td><td>129628.558827</td><td>0.968003</td><td>1.000569</td><td>1.01037</td><td>0.955292</td><td>0.998469</td><td>0.98268</td><td>0.99169</td><td>0.934768</td><td>0.946188</td><td>1.003378</td><td>0.926452</td><td>0.959538</td><td>0.981401</td><td>0.929758</td><td>1.005362</td><td>0.93798</td><td>0.432538</td><td>0.928113</td><td>0.972302</td><td>0.979695</td><td>0.36521</td><td>0.432538</td><td>1.008082</td><td>1.011252</td><td>1.019362</td><td>1.004045</td><td>0.2575</td><td>1.009855</td><td>0.956444</td><td>0.955428</td><td>0.330542</td><td>0.993248</td><td>1.012203</td><td>&hellip;</td><td>0.993399</td><td>1.011809</td><td>0.985931</td><td>0.91842</td><td>0.999955</td><td>0.999613</td><td>0.951912</td><td>0.986851</td><td>0.996148</td><td>0.971425</td><td>0.993252</td><td>0.999466</td><td>0.96457</td><td>1.044102</td><td>0.991202</td><td>0.979982</td><td>0.939855</td><td>0.951247</td><td>0.93262</td><td>0.969462</td><td>0.990618</td><td>0.995819</td><td>1.005089</td><td>0.983804</td><td>0.990518</td><td>1.000888</td><td>15.960107</td><td>0.955138</td><td>0.36521</td><td>0.97386</td><td>0.988893</td><td>0.945551</td><td>0.968957</td><td>1.010042</td><td>0.962581</td><td>1.012119</td><td>1.018447</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td><td>&quot;train&quot;</td><td>0.0</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-3.670716</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>0.0</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>0.0</td><td>0.0</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>0.0</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>0.0</td><td>-5.199337</td><td>-5.199337</td><td>&hellip;</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>1.0</td><td>-5.199337</td><td>0.0</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td><td>-5.199337</td></tr><tr><td>&quot;25%&quot;</td><td>0.0</td><td>null</td><td>112261.0</td><td>-0.692281</td><td>-0.683916</td><td>-0.661349</td><td>-0.707654</td><td>-0.639911</td><td>-0.661956</td><td>-0.682975</td><td>-0.72566</td><td>-0.623914</td><td>-0.694615</td><td>-0.694273</td><td>-0.18914</td><td>-0.685233</td><td>-0.72898</td><td>-0.668672</td><td>-0.685162</td><td>0.0</td><td>-0.58943</td><td>-0.664905</td><td>-0.687989</td><td>0.0</td><td>0.0</td><td>-0.661538</td><td>-0.678779</td><td>-0.660934</td><td>-0.673439</td><td>0.0</td><td>-0.669385</td><td>-0.683582</td><td>-0.689826</td><td>0.0</td><td>-0.676932</td><td>-0.620656</td><td>&hellip;</td><td>-0.673158</td><td>-0.669981</td><td>-0.706921</td><td>-0.590838</td><td>-0.66846</td><td>-0.683152</td><td>-0.801353</td><td>-0.674078</td><td>-0.671675</td><td>-0.720095</td><td>-0.667788</td><td>-0.690797</td><td>-0.739619</td><td>-0.639139</td><td>-0.679284</td><td>-0.674719</td><td>-0.706733</td><td>-0.742386</td><td>-0.585213</td><td>-0.684278</td><td>-0.68537</td><td>-0.669827</td><td>-0.659105</td><td>-0.676133</td><td>-0.725998</td><td>-0.678703</td><td>2.0</td><td>-0.691769</td><td>0.0</td><td>-0.710511</td><td>-0.742299</td><td>-0.649389</td><td>-0.729413</td><td>-0.677886</td><td>-0.68583</td><td>-0.711827</td><td>-0.63789</td></tr><tr><td>&quot;50%&quot;</td><td>0.0</td><td>null</td><td>224523.0</td><td>0.006309</td><td>-0.008996</td><td>0.016682</td><td>-0.0196</td><td>0.065745</td><td>0.012434</td><td>-0.032726</td><td>-0.088401</td><td>0.010419</td><td>-0.017312</td><td>-0.055705</td><td>0.646959</td><td>-0.007647</td><td>-0.088496</td><td>0.001982</td><td>-0.02256</td><td>0.0</td><td>0.020405</td><td>0.018082</td><td>-0.013939</td><td>0.0</td><td>0.0</td><td>0.012798</td><td>0.004378</td><td>0.040373</td><td>-0.018163</td><td>0.0</td><td>0.025677</td><td>-0.020052</td><td>-0.027196</td><td>0.0</td><td>0.004446</td><td>0.040472</td><td>&hellip;</td><td>-0.008121</td><td>0.00947</td><td>-0.037847</td><td>-0.011368</td><td>-0.010769</td><td>0.001322</td><td>-0.105461</td><td>-0.018274</td><td>0.003871</td><td>-0.057653</td><td>0.012044</td><td>-0.018282</td><td>-0.083092</td><td>0.060013</td><td>-0.007414</td><td>0.00467</td><td>-0.054286</td><td>-0.078996</td><td>0.06402</td><td>-0.024976</td><td>-0.006904</td><td>0.01279</td><td>0.008662</td><td>-0.029454</td><td>-0.062332</td><td>0.008902</td><td>7.0</td><td>-0.043449</td><td>0.0</td><td>-0.046435</td><td>-0.071439</td><td>0.004266</td><td>-0.074023</td><td>-0.000974</td><td>-0.013552</td><td>-0.029385</td><td>0.043789</td></tr><tr><td>&quot;75%&quot;</td><td>0.0</td><td>null</td><td>336784.0</td><td>0.57019</td><td>0.683616</td><td>0.685179</td><td>0.624145</td><td>0.732262</td><td>0.693604</td><td>0.647467</td><td>0.523013</td><td>0.660546</td><td>0.641203</td><td>0.552703</td><td>1.151262</td><td>0.662635</td><td>0.547779</td><td>0.681808</td><td>0.564729</td><td>0.0</td><td>0.604635</td><td>0.726959</td><td>0.659182</td><td>0.0</td><td>0.0</td><td>0.703839</td><td>0.667771</td><td>0.72519</td><td>0.679041</td><td>0.0</td><td>0.694114</td><td>0.630094</td><td>0.638621</td><td>0.0</td><td>0.681931</td><td>0.741677</td><td>&hellip;</td><td>0.677107</td><td>0.694779</td><td>0.626405</td><td>0.629526</td><td>0.67394</td><td>0.674505</td><td>0.495809</td><td>0.63909</td><td>0.666867</td><td>0.598246</td><td>0.697201</td><td>0.656029</td><td>0.583473</td><td>0.815852</td><td>0.649701</td><td>0.656821</td><td>0.58331</td><td>0.5549</td><td>0.702135</td><td>0.639286</td><td>0.673847</td><td>0.661386</td><td>0.690436</td><td>0.637986</td><td>0.604816</td><td>0.680579</td><td>25.0</td><td>0.580748</td><td>0.0</td><td>0.61543</td><td>0.601575</td><td>0.651249</td><td>0.589397</td><td>0.678399</td><td>0.631231</td><td>0.64525</td><td>0.725587</td></tr><tr><td>&quot;max&quot;</td><td>1.0</td><td>&quot;train&quot;</td><td>449045.0</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>3.32229</td><td>3.131317</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>3.123291</td><td>5.199337</td><td>5.199337</td><td>1.0</td><td>3.332992</td><td>3.754956</td><td>5.199337</td><td>1.0</td><td>1.0</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>1.0</td><td>5.199337</td><td>3.155643</td><td>5.199337</td><td>2.0</td><td>5.199337</td><td>5.199337</td><td>&hellip;</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>3.109056</td><td>5.199337</td><td>3.963646</td><td>3.388769</td><td>3.278826</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>57.0</td><td>5.199337</td><td>1.0</td><td>5.199337</td><td>5.199337</td><td>3.292747</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td><td>5.199337</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 504)\n",
       "┌────────────┬──────────┬────────┬────────────┬───┬────────────┬───────────┬───────────┬───────────┐\n",
       "│ statistic  ┆ target   ┆ smpl   ┆ id         ┆ … ┆ feature_49 ┆ feature_4 ┆ feature_4 ┆ feature_5 │\n",
       "│ ---        ┆ ---      ┆ ---    ┆ ---        ┆   ┆ 7          ┆ 98        ┆ 99        ┆ 00        │\n",
       "│ str        ┆ f64      ┆ str    ┆ f64        ┆   ┆ ---        ┆ ---       ┆ ---       ┆ ---       │\n",
       "│            ┆          ┆        ┆            ┆   ┆ f64        ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════════╪══════════╪════════╪════════════╪═══╪════════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ count      ┆ 449046.0 ┆ 449046 ┆ 449046.0   ┆ … ┆ 449046.0   ┆ 449046.0  ┆ 449046.0  ┆ 449046.0  │\n",
       "│ null_count ┆ 0.0      ┆ 0      ┆ 0.0        ┆ … ┆ 0.0        ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ mean       ┆ 0.011551 ┆ null   ┆ 224522.5   ┆ … ┆ -0.001039  ┆ -0.038255 ┆ -0.030217 ┆ 0.046983  │\n",
       "│ std        ┆ 0.106854 ┆ null   ┆ 129628.558 ┆ … ┆ 1.010042   ┆ 0.962581  ┆ 1.012119  ┆ 1.018447  │\n",
       "│            ┆          ┆        ┆ 827        ┆   ┆            ┆           ┆           ┆           │\n",
       "│ min        ┆ 0.0      ┆ train  ┆ 0.0        ┆ … ┆ -5.199337  ┆ -5.199337 ┆ -5.199337 ┆ -5.199337 │\n",
       "│ 25%        ┆ 0.0      ┆ null   ┆ 112261.0   ┆ … ┆ -0.677886  ┆ -0.68583  ┆ -0.711827 ┆ -0.63789  │\n",
       "│ 50%        ┆ 0.0      ┆ null   ┆ 224523.0   ┆ … ┆ -0.000974  ┆ -0.013552 ┆ -0.029385 ┆ 0.043789  │\n",
       "│ 75%        ┆ 0.0      ┆ null   ┆ 336784.0   ┆ … ┆ 0.678399   ┆ 0.631231  ┆ 0.64525   ┆ 0.725587  │\n",
       "│ max        ┆ 1.0      ┆ train  ┆ 449045.0   ┆ … ┆ 5.199337   ┆ 5.199337  ┆ 5.199337  ┆ 5.199337  │\n",
       "└────────────┴──────────┴────────┴────────────┴───┴────────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.write_parquet(\"data/test_preprocessing.parquet\", compression=\"zstd\", compression_level=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"feature_17\"].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"feature_7\"].cast(pl.Int64, strict=False).equals(data[\"feature_7\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"smpl\", \"id\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head().to_pandas(use_pyarrow_extension_array=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data.drop(\"target\"), data[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 503)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>target</th><th>smpl</th><th>id</th><th>feature_1</th><th>feature_2</th><th>feature_3</th><th>feature_4</th><th>feature_5</th><th>feature_6</th><th>feature_7</th><th>feature_8</th><th>feature_9</th><th>feature_10</th><th>feature_11</th><th>feature_12</th><th>feature_13</th><th>feature_14</th><th>feature_15</th><th>feature_16</th><th>feature_17</th><th>feature_18</th><th>feature_19</th><th>feature_20</th><th>feature_21</th><th>feature_22</th><th>feature_23</th><th>feature_24</th><th>feature_25</th><th>feature_26</th><th>feature_27</th><th>feature_28</th><th>feature_29</th><th>feature_30</th><th>feature_31</th><th>feature_32</th><th>feature_33</th><th>feature_34</th><th>&hellip;</th><th>feature_464</th><th>feature_465</th><th>feature_466</th><th>feature_467</th><th>feature_468</th><th>feature_469</th><th>feature_470</th><th>feature_471</th><th>feature_472</th><th>feature_473</th><th>feature_474</th><th>feature_475</th><th>feature_476</th><th>feature_477</th><th>feature_478</th><th>feature_479</th><th>feature_480</th><th>feature_481</th><th>feature_482</th><th>feature_483</th><th>feature_484</th><th>feature_485</th><th>feature_486</th><th>feature_487</th><th>feature_488</th><th>feature_489</th><th>feature_490</th><th>feature_491</th><th>feature_492</th><th>feature_493</th><th>feature_494</th><th>feature_495</th><th>feature_496</th><th>feature_497</th><th>feature_498</th><th>feature_499</th><th>feature_500</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>&hellip;</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>1</td><td>&quot;train&quot;</td><td>51</td><td>0.575924</td><td>0.22133</td><td>1.684064</td><td>0.108184</td><td>0.086583</td><td>0.873604</td><td>-0.981125</td><td>-1.304021</td><td>-0.666024</td><td>-0.337244</td><td>1.180272</td><td>0.029739</td><td>-1.263854</td><td>1.103023</td><td>-0.075711</td><td>-0.399112</td><td>0.0</td><td>-0.954556</td><td>-0.422704</td><td>-0.20565</td><td>0.0</td><td>0.0</td><td>1.995724</td><td>1.263619</td><td>-0.153048</td><td>1.62713</td><td>0.0</td><td>-0.917502</td><td>-1.384319</td><td>-0.564511</td><td>0.0</td><td>-0.17391</td><td>0.479087</td><td>-0.634089</td><td>&hellip;</td><td>0.046279</td><td>-0.013041</td><td>0.408524</td><td>-1.466392</td><td>1.135502</td><td>-0.130431</td><td>0.846442</td><td>0.474579</td><td>-0.503552</td><td>0.714296</td><td>-0.230602</td><td>0.313121</td><td>1.372373</td><td>2.015766</td><td>0.743366</td><td>0.520015</td><td>-0.453539</td><td>0.740631</td><td>0.028593</td><td>-0.574654</td><td>-1.433721</td><td>-0.804884</td><td>0.025428</td><td>0.093243</td><td>0.347581</td><td>-0.030351</td><td>1.0</td><td>1.325476</td><td>0.0</td><td>-0.321562</td><td>-0.683197</td><td>-1.618111</td><td>0.509566</td><td>-0.890903</td><td>0.684632</td><td>0.10125</td><td>1.468575</td></tr><tr><td>1</td><td>&quot;train&quot;</td><td>116</td><td>0.535891</td><td>0.073505</td><td>-1.285314</td><td>-0.486952</td><td>-0.132037</td><td>-0.532459</td><td>1.687938</td><td>-0.875687</td><td>-0.172725</td><td>-0.965682</td><td>0.387123</td><td>1.11267</td><td>-1.140538</td><td>-1.310603</td><td>0.421993</td><td>-0.417016</td><td>0.0</td><td>0.221355</td><td>0.438114</td><td>1.281644</td><td>0.0</td><td>0.0</td><td>0.944637</td><td>-0.241344</td><td>0.289947</td><td>0.793668</td><td>0.0</td><td>-1.493517</td><td>-0.300085</td><td>-0.606894</td><td>1.0</td><td>0.76456</td><td>1.395799</td><td>0.349063</td><td>&hellip;</td><td>0.716419</td><td>0.644251</td><td>1.069474</td><td>-0.46224</td><td>1.294645</td><td>0.420474</td><td>-0.190662</td><td>-0.799477</td><td>-0.580747</td><td>-0.979771</td><td>0.648963</td><td>0.488698</td><td>-1.702593</td><td>1.28907</td><td>0.754406</td><td>1.444602</td><td>0.894355</td><td>0.064694</td><td>-0.343533</td><td>-0.846417</td><td>0.694101</td><td>1.61691</td><td>0.342168</td><td>0.267461</td><td>0.260128</td><td>-0.065663</td><td>2.0</td><td>-2.057568</td><td>0.0</td><td>1.48217</td><td>1.710262</td><td>-0.172929</td><td>0.447836</td><td>-0.400597</td><td>1.372346</td><td>-0.339095</td><td>-1.206653</td></tr><tr><td>1</td><td>&quot;train&quot;</td><td>129</td><td>0.907321</td><td>-0.670663</td><td>-0.181707</td><td>0.160142</td><td>1.15332</td><td>0.675533</td><td>-0.601514</td><td>-1.03188</td><td>0.447099</td><td>0.933306</td><td>1.049696</td><td>-0.143409</td><td>0.289074</td><td>1.063375</td><td>0.604891</td><td>0.077759</td><td>0.0</td><td>0.238669</td><td>1.543897</td><td>-0.088067</td><td>0.0</td><td>0.0</td><td>0.216293</td><td>-1.576575</td><td>0.553923</td><td>0.13333</td><td>0.0</td><td>-1.575375</td><td>-0.084472</td><td>-0.122795</td><td>0.0</td><td>1.363174</td><td>-0.499273</td><td>0.416601</td><td>&hellip;</td><td>-0.19352</td><td>0.045254</td><td>1.221884</td><td>-0.287202</td><td>0.454189</td><td>1.599415</td><td>-0.26421</td><td>1.300249</td><td>-0.385706</td><td>2.186214</td><td>0.409925</td><td>-1.327251</td><td>-0.837308</td><td>0.906037</td><td>-0.472586</td><td>0.060089</td><td>1.164486</td><td>1.20469</td><td>0.169166</td><td>-0.126535</td><td>1.888815</td><td>-0.910683</td><td>-0.041059</td><td>-0.372387</td><td>0.771838</td><td>-0.035046</td><td>15.0</td><td>0.414452</td><td>0.0</td><td>0.840254</td><td>1.885963</td><td>0.440201</td><td>0.595312</td><td>0.081776</td><td>-0.911395</td><td>0.250122</td><td>-0.02454</td></tr><tr><td>1</td><td>&quot;train&quot;</td><td>391</td><td>1.595058</td><td>-0.678757</td><td>0.135097</td><td>-0.531307</td><td>0.167596</td><td>-0.666086</td><td>-0.018718</td><td>-1.951071</td><td>-0.225989</td><td>-0.490973</td><td>0.380046</td><td>1.489469</td><td>0.780963</td><td>0.583641</td><td>-1.01475</td><td>-0.38029</td><td>0.0</td><td>-0.102469</td><td>0.169021</td><td>0.458915</td><td>0.0</td><td>0.0</td><td>-0.892611</td><td>-1.143362</td><td>-0.093893</td><td>-2.69318</td><td>0.0</td><td>0.229763</td><td>-1.485948</td><td>-1.20618</td><td>0.0</td><td>0.440022</td><td>1.3</td><td>0.92657</td><td>&hellip;</td><td>-1.187309</td><td>-0.219683</td><td>0.526998</td><td>-0.456207</td><td>-1.948905</td><td>-2.877563</td><td>-1.360259</td><td>0.094024</td><td>1.522478</td><td>0.756947</td><td>0.321435</td><td>0.790942</td><td>1.420553</td><td>1.131217</td><td>0.750021</td><td>-0.831505</td><td>0.409404</td><td>-0.164877</td><td>0.479127</td><td>-0.142328</td><td>-0.129153</td><td>-2.353522</td><td>0.899784</td><td>1.054675</td><td>-0.423816</td><td>0.593567</td><td>2.0</td><td>-0.818523</td><td>0.0</td><td>-0.392109</td><td>-0.234374</td><td>-0.232281</td><td>-0.158962</td><td>0.223449</td><td>0.989992</td><td>0.579262</td><td>-1.272855</td></tr><tr><td>1</td><td>&quot;train&quot;</td><td>417</td><td>-0.633544</td><td>-0.810396</td><td>0.430721</td><td>-0.298063</td><td>2.619097</td><td>2.096483</td><td>-0.01499</td><td>0.592974</td><td>-1.098315</td><td>-2.06642</td><td>0.305547</td><td>0.536667</td><td>1.02318</td><td>0.158979</td><td>1.04366</td><td>0.134349</td><td>0.0</td><td>-0.878825</td><td>0.181724</td><td>1.541455</td><td>0.0</td><td>0.0</td><td>1.689923</td><td>-1.739879</td><td>-1.05516</td><td>1.458465</td><td>0.0</td><td>-0.96353</td><td>-0.274656</td><td>-0.146203</td><td>1.0</td><td>0.561834</td><td>-0.293778</td><td>0.775582</td><td>&hellip;</td><td>1.553534</td><td>2.508949</td><td>-1.043853</td><td>-0.841256</td><td>-0.416662</td><td>-1.466668</td><td>0.153301</td><td>0.078719</td><td>1.36361</td><td>0.572639</td><td>-0.69381</td><td>-1.141616</td><td>-0.544009</td><td>1.053136</td><td>0.437316</td><td>-1.828404</td><td>0.864916</td><td>-2.086519</td><td>-0.276042</td><td>-0.002167</td><td>0.122965</td><td>0.312188</td><td>-0.413563</td><td>-1.594506</td><td>0.097207</td><td>0.092639</td><td>4.0</td><td>-0.261561</td><td>0.0</td><td>-0.826684</td><td>-2.335803</td><td>-0.569552</td><td>0.414016</td><td>0.303864</td><td>0.241606</td><td>-1.015104</td><td>-0.975828</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 503)\n",
       "┌────────┬───────┬─────┬───────────┬───┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ target ┆ smpl  ┆ id  ┆ feature_1 ┆ … ┆ feature_497 ┆ feature_498 ┆ feature_499 ┆ feature_500 │\n",
       "│ ---    ┆ ---   ┆ --- ┆ ---       ┆   ┆ ---         ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ i64    ┆ str   ┆ i64 ┆ f32       ┆   ┆ f32         ┆ f32         ┆ f32         ┆ f32         │\n",
       "╞════════╪═══════╪═════╪═══════════╪═══╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ 1      ┆ train ┆ 51  ┆ 0.575924  ┆ … ┆ -0.890903   ┆ 0.684632    ┆ 0.10125     ┆ 1.468575    │\n",
       "│ 1      ┆ train ┆ 116 ┆ 0.535891  ┆ … ┆ -0.400597   ┆ 1.372346    ┆ -0.339095   ┆ -1.206653   │\n",
       "│ 1      ┆ train ┆ 129 ┆ 0.907321  ┆ … ┆ 0.081776    ┆ -0.911395   ┆ 0.250122    ┆ -0.02454    │\n",
       "│ 1      ┆ train ┆ 391 ┆ 1.595058  ┆ … ┆ 0.223449    ┆ 0.989992    ┆ 0.579262    ┆ -1.272855   │\n",
       "│ 1      ┆ train ┆ 417 ┆ -0.633544 ┆ … ┆ 0.303864    ┆ 0.241606    ┆ -1.015104   ┆ -0.975828   │\n",
       "└────────┴───────┴─────┴───────────┴───┴─────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pl.read_parquet(\"../data/sub_train_dataset.parquet\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clearml import Task\n",
    "import pickle\n",
    "\n",
    "# Подключение к задаче ClearML, которая содержит вашу модель\n",
    "task = Task.get_task(project_name=\"Alfa_hack\", task_name=\"Blending Catboost train full_dataset 07.11.24 v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_local_copy_of_the_previously_uploaded_artifact = task.artifacts[\"catboost_weights\"].get_local_copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(my_local_copy_of_the_previously_uploaded_artifact, \"rb\") as file:\n",
    "    model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "Invalid type for cat_feature[non-default value idx=0,feature_idx=30]=0.0 : cat_features must be integer or string, real number values and NaN values should be converted to string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m_catboost.pyx:2613\u001b[0m, in \u001b[0;36m_catboost.get_cat_factor_bytes_representation\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:2128\u001b[0m, in \u001b[0;36m_catboost.get_id_object_bytes_string_representation\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: bad object for id: 0.0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msmpl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_pyarrow_extension_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/alfa-hack-2024/venv/lib/python3.12/site-packages/catboost/core.py:5307\u001b[0m, in \u001b[0;36mCatBoostClassifier.predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\u001b[0m\n\u001b[1;32m   5250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, prediction_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m, ntree_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ntree_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, thread_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   5251\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5252\u001b[0m \u001b[38;5;124;03m    Predict with data.\u001b[39;00m\n\u001b[1;32m   5253\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5305\u001b[0m \u001b[38;5;124;03m              with log probability for every class for each object.\u001b[39;00m\n\u001b[1;32m   5306\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntree_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/alfa-hack-2024/venv/lib/python3.12/site-packages/catboost/core.py:2620\u001b[0m, in \u001b[0;36mCatBoost._predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name, task_type)\u001b[0m\n\u001b[1;32m   2618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2619\u001b[0m     verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 2620\u001b[0m data, data_is_single_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_predict_input_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_method_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_prediction_type(prediction_type)\n\u001b[1;32m   2623\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_predict(data, prediction_type, ntree_start, ntree_end, thread_count, verbose, task_type)\n",
      "File \u001b[0;32m~/alfa-hack-2024/venv/lib/python3.12/site-packages/catboost/core.py:2600\u001b[0m, in \u001b[0;36mCatBoost._process_predict_input_data\u001b[0;34m(self, data, parent_method_name, thread_count, label)\u001b[0m\n\u001b[1;32m   2598\u001b[0m is_single_object \u001b[38;5;241m=\u001b[39m _is_data_single_object(data)\n\u001b[1;32m   2599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Pool):\n\u001b[0;32m-> 2600\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_single_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_cat_feature_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFeaturesData\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_text_feature_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFeaturesData\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2605\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_embedding_feature_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFeaturesData\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthread_count\u001b[49m\n\u001b[1;32m   2607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data, is_single_object\n",
      "File \u001b[0;32m~/alfa-hack-2024/venv/lib/python3.12/site-packages/catboost/core.py:855\u001b[0m, in \u001b[0;36mPool.__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, graph, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr, data_can_be_none)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature_names, PATH_TYPES):\n\u001b[1;32m    850\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\n\u001b[1;32m    851\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names must be None or have non-string type when the pool is created from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    852\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    853\u001b[0m             )\n\u001b[0;32m--> 855\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_can_be_none:\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/alfa-hack-2024/venv/lib/python3.12/site-packages/catboost/core.py:1491\u001b[0m, in \u001b[0;36mPool._init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1490\u001b[0m     feature_tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_transform_tags(feature_tags, feature_names)\n\u001b[0;32m-> 1491\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m                \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m_catboost.pyx:4339\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4391\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4200\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:3100\u001b[0m, in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:2620\u001b[0m, in \u001b[0;36m_catboost.get_cat_factor_bytes_representation\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: Invalid type for cat_feature[non-default value idx=0,feature_idx=30]=0.0 : cat_features must be integer or string, real number values and NaN values should be converted to string."
     ]
    }
   ],
   "source": [
    "model.predict(data.drop([\"target\", \"smpl\", \"id\"]).sample(1).to_pandas(use_pyarrow_extension_array=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
